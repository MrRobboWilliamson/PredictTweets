REGISTER 'hdfs://data7201-node1.fabric.zones.eait.uq.edu.au:8020/user/hdfs/json-simple-1.1.jar';
REGISTER 'hdfs://data7201-node1.fabric.zones.eait.uq.edu.au:8020//user/hdfs/elephant-bird-hadoop-compat-4.1.jar';
REGISTER 'hdfs://data7201-node1.fabric.zones.eait.uq.edu.au:8020//user/hdfs/elephant-bird-pig-4.1.jar';

-- this is just one day, there is a bunch more data, once the script is working well
tweets_all = LOAD '/data/ProjectDataset/statuses.log.2014*' USING com.twitter.elephantbird.pig.load.JsonLoader('-nestedLoad') AS (json:map[]);

-- to get the geo locations of tweets
tweets_all = FOREACH tweets_all GENERATE FLATTEN(json#'created_at') as time_stamp, FLATTEN(json#'id') as id, FLATTEN(json#'coordinates') as (coords:map[]), FLATTEN(json#'place') as (place:map[]);

-- ensure that we remove duplicates
tweets = DISTINCT tweets_all;

-- filter for tweets with geo or place tags
filtered = FILTER tweets BY (coords IS NOT NULL) OR (place IS NOT NULL);

-- parse the date time
time_stamps1 = foreach filtered generate ToDate(time_stamp, 'EEE MMM dd HH:mm:ss Z yyyy') as time_stamp:DateTime, id as id;

-- just get the date from the datetime
time_stamps2 = foreach time_stamps1 generate id, CONCAT((chararray)GetYear(time_stamp),'-',(chararray)GetMonth(time_stamp),'-',(chararray)GetDay(time_stamp)) as date_string:chararray;

-- group by the date and count
by_date = group time_stamps2 by date_string;

-- count the number of records on each day
daily_count = foreach by_date generate Flatten(group) as day:chararray, COUNT(time_stamps2) as num_tweets:int;

-- dump the filtered data and count the number of records
STORE daily_count INTO 'hdfs://data7201-node1.fabric.zones.eait.uq.edu.au:8020/user/s4575121/project_output/geo_by_day' USING PigStorage('|');

